{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb41d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/moving-average-smoothing-for-time-series-forecasting-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9ebed",
   "metadata": {},
   "source": [
    "## Moving Average as Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2bd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = read_csv('d:/Mubassira/AirPassengers.csv', header=0, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476dba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(series.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc10902e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  112\n",
       "1  118\n",
       "2  132\n",
       "3  129\n",
       "4  121"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30e51c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean    t-1    t+1    t+2  t+3\n",
      "0     NaN    NaN    NaN    NaN  112\n",
      "1     NaN  112.0    NaN    NaN  118\n",
      "2     NaN  118.0  112.0    NaN  132\n",
      "3     NaN  132.0  118.0  112.0  129\n",
      "4     NaN  129.0  132.0  118.0  121\n",
      "5     NaN  121.0  129.0  132.0  135\n",
      "6  122.75  135.0  121.0  129.0  148\n",
      "7  125.00  148.0  135.0  121.0  148\n",
      "8  129.25  148.0  148.0  135.0  136\n",
      "9  133.25  136.0  148.0  148.0  119\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame(series.values)\n",
    "width = 3\n",
    "lag1 = df.shift(1)\n",
    "lag2= df.shift(2)\n",
    "lag3 = df.shift(width - 1)\n",
    "window = lag3.rolling(window=width)\n",
    "means = window.mean()\n",
    "dataframe = concat([means, lag1,lag2, df], axis=1)\n",
    "dataframe.columns = ['mean', 't-1', 't+1','t+2']\n",
    "print(dataframe.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cdbfefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "######  https://machinelearningmastery.com/random-forest-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc2aa69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest for time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e067de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an random forest model and make a one step prediction\n",
    "def random_forest_forecast(train, testX):\n",
    "    # transform list into array\n",
    "    train = asarray(train)\n",
    "    # split into input and output columns\n",
    "    trainX, trainy = train[:, :-1], train[:, -1]\n",
    "    # fit model\n",
    "    model = RandomForestRegressor(n_estimators=10000)\n",
    "    model.fit(trainX, trainy)\n",
    "    # make a one-step prediction\n",
    "    yhat = model.predict([testX])\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # split test row into input and output columns\n",
    "        testX, testy = test[i, :-1], test[i, -1]\n",
    "        # fit model on history and make a prediction\n",
    "        yhat = random_forest_forecast(history, testX)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "        # summarize progress\n",
    "        print('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "    # estimate prediction error\n",
    "    error = mean_absolute_error(test[:, -1], predictions)\n",
    "    return error, test[:, -1], predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0c7b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# load the dataset\n",
    "series = read_csv('d:/Mubassira/AirPassengers.csv', header=0, index_col=0)\n",
    "values = series.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "919bd706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c919a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112., 118., 132., 129.],\n",
       "       [118., 132., 129., 121.],\n",
       "       [132., 129., 121., 135.],\n",
       "       [129., 121., 135., 148.],\n",
       "       [121., 135., 148., 148.],\n",
       "       [135., 148., 148., 136.],\n",
       "       [148., 148., 136., 119.],\n",
       "       [148., 136., 119., 104.],\n",
       "       [136., 119., 104., 118.],\n",
       "       [119., 104., 118., 115.],\n",
       "       [104., 118., 115., 126.],\n",
       "       [118., 115., 126., 141.],\n",
       "       [115., 126., 141., 135.],\n",
       "       [126., 141., 135., 125.],\n",
       "       [141., 135., 125., 149.],\n",
       "       [135., 125., 149., 170.],\n",
       "       [125., 149., 170., 170.],\n",
       "       [149., 170., 170., 158.],\n",
       "       [170., 170., 158., 133.],\n",
       "       [170., 158., 133., 114.],\n",
       "       [158., 133., 114., 140.],\n",
       "       [133., 114., 140., 145.],\n",
       "       [114., 140., 145., 150.],\n",
       "       [140., 145., 150., 178.],\n",
       "       [145., 150., 178., 163.],\n",
       "       [150., 178., 163., 172.],\n",
       "       [178., 163., 172., 178.],\n",
       "       [163., 172., 178., 199.],\n",
       "       [172., 178., 199., 199.],\n",
       "       [178., 199., 199., 184.],\n",
       "       [199., 199., 184., 162.],\n",
       "       [199., 184., 162., 146.],\n",
       "       [184., 162., 146., 166.],\n",
       "       [162., 146., 166., 171.],\n",
       "       [146., 166., 171., 180.],\n",
       "       [166., 171., 180., 193.],\n",
       "       [171., 180., 193., 181.],\n",
       "       [180., 193., 181., 183.],\n",
       "       [193., 181., 183., 218.],\n",
       "       [181., 183., 218., 230.],\n",
       "       [183., 218., 230., 242.],\n",
       "       [218., 230., 242., 209.],\n",
       "       [230., 242., 209., 191.],\n",
       "       [242., 209., 191., 172.],\n",
       "       [209., 191., 172., 194.],\n",
       "       [191., 172., 194., 196.],\n",
       "       [172., 194., 196., 196.],\n",
       "       [194., 196., 196., 236.],\n",
       "       [196., 196., 236., 235.],\n",
       "       [196., 236., 235., 229.],\n",
       "       [236., 235., 229., 243.],\n",
       "       [235., 229., 243., 264.],\n",
       "       [229., 243., 264., 272.],\n",
       "       [243., 264., 272., 237.],\n",
       "       [264., 272., 237., 211.],\n",
       "       [272., 237., 211., 180.],\n",
       "       [237., 211., 180., 201.],\n",
       "       [211., 180., 201., 204.],\n",
       "       [180., 201., 204., 188.],\n",
       "       [201., 204., 188., 235.],\n",
       "       [204., 188., 235., 227.],\n",
       "       [188., 235., 227., 234.],\n",
       "       [235., 227., 234., 264.],\n",
       "       [227., 234., 264., 302.],\n",
       "       [234., 264., 302., 293.],\n",
       "       [264., 302., 293., 259.],\n",
       "       [302., 293., 259., 229.],\n",
       "       [293., 259., 229., 203.],\n",
       "       [259., 229., 203., 229.],\n",
       "       [229., 203., 229., 242.],\n",
       "       [203., 229., 242., 233.],\n",
       "       [229., 242., 233., 267.],\n",
       "       [242., 233., 267., 269.],\n",
       "       [233., 267., 269., 270.],\n",
       "       [267., 269., 270., 315.],\n",
       "       [269., 270., 315., 364.],\n",
       "       [270., 315., 364., 347.],\n",
       "       [315., 364., 347., 312.],\n",
       "       [364., 347., 312., 274.],\n",
       "       [347., 312., 274., 237.],\n",
       "       [312., 274., 237., 278.],\n",
       "       [274., 237., 278., 284.],\n",
       "       [237., 278., 284., 277.],\n",
       "       [278., 284., 277., 317.],\n",
       "       [284., 277., 317., 313.],\n",
       "       [277., 317., 313., 318.],\n",
       "       [317., 313., 318., 374.],\n",
       "       [313., 318., 374., 413.],\n",
       "       [318., 374., 413., 405.],\n",
       "       [374., 413., 405., 355.],\n",
       "       [413., 405., 355., 306.],\n",
       "       [405., 355., 306., 271.],\n",
       "       [355., 306., 271., 306.],\n",
       "       [306., 271., 306., 315.],\n",
       "       [271., 306., 315., 301.],\n",
       "       [306., 315., 301., 356.],\n",
       "       [315., 301., 356., 348.],\n",
       "       [301., 356., 348., 355.],\n",
       "       [356., 348., 355., 422.],\n",
       "       [348., 355., 422., 465.],\n",
       "       [355., 422., 465., 467.],\n",
       "       [422., 465., 467., 404.],\n",
       "       [465., 467., 404., 347.],\n",
       "       [467., 404., 347., 305.],\n",
       "       [404., 347., 305., 336.],\n",
       "       [347., 305., 336., 340.],\n",
       "       [305., 336., 340., 318.],\n",
       "       [336., 340., 318., 362.],\n",
       "       [340., 318., 362., 348.],\n",
       "       [318., 362., 348., 363.],\n",
       "       [362., 348., 363., 435.],\n",
       "       [348., 363., 435., 491.],\n",
       "       [363., 435., 491., 505.],\n",
       "       [435., 491., 505., 404.],\n",
       "       [491., 505., 404., 359.],\n",
       "       [505., 404., 359., 310.],\n",
       "       [404., 359., 310., 337.],\n",
       "       [359., 310., 337., 360.],\n",
       "       [310., 337., 360., 342.],\n",
       "       [337., 360., 342., 406.],\n",
       "       [360., 342., 406., 396.],\n",
       "       [342., 406., 396., 420.],\n",
       "       [406., 396., 420., 472.],\n",
       "       [396., 420., 472., 548.],\n",
       "       [420., 472., 548., 559.],\n",
       "       [472., 548., 559., 463.],\n",
       "       [548., 559., 463., 407.],\n",
       "       [559., 463., 407., 362.],\n",
       "       [463., 407., 362., 405.],\n",
       "       [407., 362., 405., 417.],\n",
       "       [362., 405., 417., 391.],\n",
       "       [405., 417., 391., 419.],\n",
       "       [417., 391., 419., 461.],\n",
       "       [391., 419., 461., 472.],\n",
       "       [419., 461., 472., 535.],\n",
       "       [461., 472., 535., 622.],\n",
       "       [472., 535., 622., 606.],\n",
       "       [535., 622., 606., 508.],\n",
       "       [622., 606., 508., 461.],\n",
       "       [606., 508., 461., 390.],\n",
       "       [508., 461., 390., 432.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec75887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 12)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs predicted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16917e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f5eda6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2443.7313293200014"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106807ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
